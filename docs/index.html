<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Home | AI Practitioner</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Home" />
<meta name="author" content="John Michael Miller" />
<meta property="og:locale" content="en" />
<meta name="description" content="jMM’s AI Practitioner Blog" />
<meta property="og:description" content="jMM’s AI Practitioner Blog" />
<link rel="canonical" href="https://blog.pdata.com/" />
<meta property="og:url" content="https://blog.pdata.com/" />
<meta property="og:site_name" content="AI Practitioner" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Home" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","author":{"@type":"Person","name":"John Michael Miller"},"description":"jMM’s AI Practitioner Blog","headline":"Home","name":"AI Practitioner","url":"https://blog.pdata.com/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://blog.pdata.com/feed.xml" title="AI Practitioner" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">AI Practitioner</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/">Home</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="home"><h1 class="page-heading">Home</h1><h1 id="ai-practitioner">AI Practitioner</h1>

<p>Welcome to jMM’s AI Practitioner Blog.</p>
<h2 class="post-list-heading">Posts</h2>
    <ul class="post-list"><li><div class="post-item"><div class="post-content">
            <span class="post-meta">Jan 26, 2026</span>
            <h3>
              <a class="post-link" href="/AIAGSD4/">
                AI-Assisted Greenfield Software Development, Part 4: Architecture Instruction Files
              </a>
            </h3><h1 id="ai-assisted-greenfield-software-development-part-4-architecture-prompts-and-instructions">AI-Assisted Greenfield Software Development, Part 4: Architecture Prompts and Instructions</h1>

<p>This is the fourth post in the series on AI‑assisted greenfield software development. If you’re joining mid‑stream, you may want to begin with <a href="https://blog.pdata.com/AIAGSD1/">Part 1: Business Requirements</a>, where we established the foundation for an AI‑driven development workflow. Parts 2 and 3 expanded that foundation with scaffolding, project‑level instructions, and Git workflow guidance.</p>

<p>In this post, we shift from <em>project‑level</em> instructions to <em>architecture‑level</em> instructions. This is where we define the structural rules that guide AI agents as they generate code—ensuring consistency, correctness, and architectural integrity across the entire solution.</p>

<hr />

<h2 id="why-architecture-instruction-files-matter">Why Architecture Instruction Files Matter</h2>

<p>When humans build software, architecture is often implicit—shared understanding, tribal knowledge, and experience fill in the gaps. AI doesn’t have that luxury. Without explicit architectural rules, AI agents tend to optimize for convenience rather than coherence.</p>

<p>Architecture instruction files solve this by providing:</p>

<ul>
  <li>A clear architectural pattern</li>
  <li>Implementation rules and constraints</li>
  <li>Folder and feature structure</li>
  <li>Cross‑cutting concerns</li>
  <li>Anti‑patterns to avoid</li>
  <li>Testing expectations</li>
  <li>Success criteria for generated code</li>
</ul>

<p>These files become the “rails” that keep AI‑generated code aligned with the intended system design.</p>

<p>In <a href="https://blog.pdata.com/AIAGSD4/">Part 4</a>, we focus on one of the most widely used architectural patterns in modern backend systems: <code class="language-plaintext highlighter-rouge">CQRS</code>. I’ve chosen <code class="language-plaintext highlighter-rouge">CQRS</code> because it is not a trivial architecture and is a good test of AI’s ability to create architectural instructions and implement in accordance with those instructions.</p>

<hr />

<h2 id="what-is-cqrs">What Is CQRS?</h2>

<p>The <code class="language-plaintext highlighter-rouge">CQRS</code> (Command Query Responsibility Segregation) architectural pattern separates read operations (queries) from write operations (commands). Instead of a single model handling everything, <code class="language-plaintext highlighter-rouge">CQRS</code> splits responsibilities so each side can be optimized independently.</p>

<h3 id="core-principle">Core Principle</h3>

<p>Traditional <code class="language-plaintext highlighter-rouge">CRUD</code> applications use a single model to handle both read and write operations. <code class="language-plaintext highlighter-rouge">CQRS</code> separates these concerns by introducing two distinct models: one dedicated to commands (writes) and another focused on queries (reads).</p>

<p><strong>Commands</strong></p>

<p>A command is responsible for modifying the system’s state and carrying out the necessary business logic to make that change meaningful. Its job ends there—it does not return any domain‑level data, only an acknowledgment that the operation completed. Command examples are <code class="language-plaintext highlighter-rouge">CreateOrderCommand</code> and <code class="language-plaintext highlighter-rouge">ChangePasswordCommand</code></p>

<p><strong>Queries</strong></p>

<p>A query’s sole responsibility is to retrieve information from the system. It provides data back to the caller but never alters application state or triggers any side effects</p>

<h3 id="key-benefits">Key Benefits</h3>

<p><code class="language-plaintext highlighter-rouge">CQRS</code> makes it possible to scale the read and write sides of the system independently, allowing each to grow according to its own demands. Because the two responsibilities are separated, each side can use models tailored to its specific purpose, with the read side often taking advantage of denormalized structures to maximize performance. This separation also creates cleaner security boundaries, making it easier to control who can read or modify data. And since the two sides operate independently, each can use the storage technology best suited to its workload, giving the architecture far more flexibility overall</p>

<h3 id="common-implementation-pattern">Common Implementation Pattern</h3>

<p>Write operations trigger events that update read models. This creates an <em>eventually consistent</em> system—an intentional tradeoff that unlocks performance and scalability.</p>

<h3 id="when-cqrs-is-a-good-fit">When <code class="language-plaintext highlighter-rouge">CQRS</code> Is a Good Fit</h3>

<p><code class="language-plaintext highlighter-rouge">CQRS</code> is especially effective in environments where read operations vastly outnumber writes, allowing the system to optimize each side independently. It also shines in domains with intricate business rules, where separating commands and queries helps keep complexity manageable. Architectures built around event sourcing benefit naturally from <code class="language-plaintext highlighter-rouge">CQRS</code>, as do multi‑tenant applications that must serve diverse read patterns. And in systems where auditability is essential, the clear separation of responsibilities makes tracking and verifying changes far more straightforward.</p>

<h3 id="when-to-avoid-it">When to Avoid It</h3>

<p>If your application is simple <code class="language-plaintext highlighter-rouge">CRUD</code>, <code class="language-plaintext highlighter-rouge">CQRS</code> adds complexity without meaningful benefit.</p>

<hr />

<h2 id="creating-the-architecture-prompt-file">Creating the Architecture Prompt File</h2>

<p>Prior to creating CQRS instructions, I created a prompt file to guide the creation of the instructions. By asking Copilot to create a prompt file, you give Copilot a chance to add relevant context to the which improves the prompt, which in turn will improve the instructions generated by the prompt.</p>

<p>When generating GitHub AI guidance I used the custom <a href="https://github.com/johnmillerATcodemag-com/zeus.academia.3b/blob/a0ce78c1e527432044f574dafe4cca7cdacdd099/.github/chatmodes/prompt-engineer.chatmode.md">prompt-engineer.chatmode.md</a> chat mode, introduced in <a href="https://blog.pdata.com/AIAGSD2/">Part 2</a>, which focuses Copilot on the skills needed to generate effective prompts.</p>

<p>When working with GitHub AI guidance there is always a chicken-and-egg problem. For Copilot to generate an artifact, you need a prompt. In this case we want Copilot to generate a prompt file. We could create a prompt file that would generate the prompt file we need to generate the instruction file. This is a recursive process with diminishing returns. At some point we’d need to manually prompt Copilot to bootstrap the artifact generation.</p>

<p>Here is the manual prompt I used to generate the prompt file: <em>Create a prompt file that generates instruction files for a CQRS architecture. The prompt file should target AI agents and be optimized to reduce token consumption.</em></p>

<p>By asking Copilot to generate a prompt file, Copilot will use the <a href="https://github.com/johnmillerATcodemag-com/zeus.academia.3b/blob/a0ce78c1e527432044f574dafe4cca7cdacdd099/.github/instructions/ai-assisted-output.instructions.md">ai-assisted-output.instructions.md</a> and the <a href="https://github.com/johnmillerATcodemag-com/zeus.academia.3b/blob/a0ce78c1e527432044f574dafe4cca7cdacdd099/.github/instructions/prompt-file-generation.instructions.md">prompt-file-generation.instructions.md</a> to guide the generation of the prompt file. This ensures the prompt file conforms to the AI output instructions and the instructions for generating prompts.</p>

<p>All of this meta guidance (prompts that generate prompts which create instructions that govern the generation of code) can get confusing. Take a close look at the files I’ve referenced in this post and have Copilot explain anything you don’t quite understand.</p>

<hr />

<h3 id="understanding-the-generate-cqrs-eventsourcing-instructionspromptmd-prompt-file">Understanding the <a href="https://github.com/johnmillerATcodemag-com/zeus.academia.3b/blob/13fc7e8eb6fa47a5f933cd0e427dc7c65642f5c0/.github/prompts/generate-cqrs-eventsourcing-instructions.prompt.md">generate-cqrs-eventsourcing-instructions.prompt.md</a> prompt file.</h3>

<p>The <a href="https://github.com/johnmillerATcodemag-com/zeus.academia.3b/blob/13fc7e8eb6fa47a5f933cd0e427dc7c65642f5c0/.github/prompts/generate-cqrs-eventsourcing-instructions.prompt.md">generate-cqrs-eventsourcing-instructions.prompt.md</a> prompt file instructs an AI agent to generate a complete instruction file for implementing CQRS with Event Sourcing patterns in a specific programming language and technology stack. The agent takes four parameters, the programming language, mediator framework, event store implementation, and projection strategy, and produces a comprehensive .instructions.md file that will guide future AI-assisted code generation.</p>

<p>The instruction file content follows a rigid 15-section structure. The agent begins with a brief overview, then creates a reference table defining core concepts like events, aggregates, event stores, projections, and snapshots. It documents three main implementation patterns, command handling with event-sourced aggregates, event store operations for writing and reading event streams, and query handling using projections rather than direct event store access.</p>

<p>For each pattern, the agent provides structure tables showing components, their purposes, and file locations, followed by implementation rules written as imperative directives. It includes minimal code templates demonstrating aggregate event application, command handlers that append events with optimistic concurrency, and projection subscribers that update read models. The agent specifies snapshot strategies for performance optimization when aggregates accumulate many events, and documents the chosen projection approach (inline, background worker, or separate service).</p>

<p>Additional sections cover event schema design with versioning strategies, aggregate reconstruction patterns, idempotency handling, anti-patterns to avoid, event schema evolution techniques using upcasters, and testing approaches. The agent concludes with a validation checklist ensuring all critical patterns are documented.</p>

<hr />

<h2 id="creating-the-architecture-instruction-file">Creating the Architecture Instruction File</h2>

<p>With the prompt file in place, I generated a concrete instruction file. Using the prompt:</p>

<p><em>Submit the prompt generate-cqrs-eventsourcing-instructions.prompt.md in the C# language, the MediatR framework, the EventStoreDB event_store and inline projections</em></p>

<p>This generates an instruction that directs AI agents to generate C# code that strictly separates command handling from query handling, using MediatR for mediation and EventStoreDB for persistence. When creating commands, agents must structure them so handlers validate inputs, load aggregates by replaying events, execute domain logic that returns new events without mutating state, and append those events using optimistic concurrency checks. Agents are instructed to never allow aggregates to directly modify their internal state; instead, all state changes must flow through Apply() methods that process events.</p>

<p>For queries, agents must create handlers that read exclusively from denormalized read models stored in a separate database schema, never directly accessing the event store. The file mandates inline projections that update read models synchronously within the same transaction as event appends, ensuring immediate consistency. Agents must implement projection classes with event handler methods that transform events into read model updates.</p>

<p>When building aggregates, agents are directed to implement Apply() methods for rebuilding state from event streams and command methods that validate business rules then yield new events. The file prohibits direct property setters and requires immutable event types, preferably using C# records. Agents must name event streams following the “{aggregate}-{id}” pattern and include full metadata with each event.</p>

<p>For performance optimization, agents are instructed to implement snapshot stores that cache aggregate state when streams exceed 50-100 events, loading aggregates from the latest snapshot plus subsequent events rather than replaying entire streams. The file directs agents to handle event versioning through upcaster classes that transform old event formats during reads.</p>

<p>Agents must implement idempotency through MediatR pipeline behaviors that track command identifiers and prevent duplicate processing. Testing code should follow Given-When-Then patterns, verifying events produced by commands, read model updates from projections, and state transitions in aggregates.</p>

<p>The instruction file explicitly prohibits several patterns: querying event stores for reads, mutating aggregate state outside event application, deleting events, sharing events between aggregates, and loading multiple aggregates in command handlers. It enforces a strict project structure segregating commands, queries, projections, aggregates, events, and infrastructure concerns into designated directories.</p>

<p>Throughout, agents are directed to use MediatR’s IRequestHandler interface for all command and query handlers, EventStoreDB’s AppendAsync with ExpectedVersion for writes, and dedicated read database contexts for queries. The file provides code templates showing exactly how to structure each component, ensuring agents generate consistent, pattern-compliant implementations.</p>

<p>At this point, the AI has:</p>

<ul>
  <li>Business requirements</li>
  <li>Project‑level instructions</li>
  <li>Architecture‑level instructions</li>
</ul>

<p>To complete the foundation we need technology specific instructions and project implementation guidance.</p>

<hr />

<h2 id="checking-the-context">Checking the Context</h2>

<p>Before moving on, it’s a good idea to review the .github governance (prompts, instructions, etc.) as whole to make sure there aren’t conflicting governance that could confuse Copilot. In <a href="https://blog.pdata.com/AIAGSD2/">Part 2</a> I introduced the check-context.prompt.md file that examines the current context and reports any anomalies that should be addressed.</p>

<p>Here is the Quality Assessment portion of the analysis:</p>

<p>✅ Complete AI provenance metadata (all required fields)
✅ Copilot prompt metadata (description, context, expected_output)
✅ Optional fields included (tools, mode) for enhanced functionality
✅ Token-optimized content (~200 tokens core content)
✅ Clear structured output format (YAML for parseability)
✅ Actionable 6-step validation workflow
✅ Comprehensive 7-category conflict detection
✅ Conversation and summary logs complete</p>

<p>This is a prompt that should be submitted any time the .github governance changes. Copilot didn’t find any issues to address, so we are good to proceed.</p>

<hr />

<h2 id="whats-next">What’s Next?</h2>

<p>In Part 5, I’ll add instruction files for the technologies we’re implementing. These instructions will guide Copilot in the details for implementing specific technologies. We’ll cover naming conventions, patterns, namespaces, standards, and templates for implementing the classes that will be implemented.</p>

<p>If you’d like to explore the files or follow along with your own implementation, everything is available in the Academia GitHub repository. Fork it, experiment, and adapt it to your own workflow.</p>

<hr />

<h2 id="feedback-loop">Feedback Loop</h2>

<p>Feedback is always welcome. Send your thoughts to <strong>AIP@pdata.com</strong>.</p>

<hr />

<h2 id="disclaimer">Disclaimer</h2>

<p>AI contributed to the writing of this post, but humans reviewed it, refined it, enhanced it, and gave it soul.</p>

<p>Prompts:</p>

<ul>
  <li>Rephrase these points as prose:
    <ul>
      <li>Traditional: In a typical <code class="language-plaintext highlighter-rouge">CRUD</code> application, one model handles both reads and writes</li>
      <li><code class="language-plaintext highlighter-rouge">CQRS</code>: With <code class="language-plaintext highlighter-rouge">CQRS</code>, there are two models—one for commands, one for queries</li>
    </ul>
  </li>
  <li>Summarize <code class="language-plaintext highlighter-rouge">generate-csharp-implementation-instructions.prompt.md</code> in prose. Don’t explain CQRS or Event Sourcing. Describe what the file instructs an AI agent to do.</li>
  <li>Summarize <code class="language-plaintext highlighter-rouge">generate-cqrs-eventsourcing-instructions.prompt.md</code> in prose. don’t explain CQRS or Event Sourcing. Describe what the file instructs an AI agent to do.</li>
  <li>Write a paragraph defining Event Sourcing</li>
  <li>
    <h2 id="explain-the-cqrs-architecture-pattern">Explain the <code class="language-plaintext highlighter-rouge">CQRS</code> architecture pattern</h2>
  </li>
</ul>
</div>
        </div>
      </li><li><div class="post-item"><a href="/WTAIP/" class="post-image-link">
              <img src="/assets/images/2026-01-20/header-WTAIP.jpg" alt="Welcome to the AI Practitioner&#39;s Blog" class="post-thumbnail" />
            </a><div class="post-content">
            <span class="post-meta">Jan 20, 2026</span>
            <h3>
              <a class="post-link" href="/WTAIP/">
                Welcome to the AI Practitioner&#39;s Blog
              </a>
            </h3><p>This is the retro-inaugural post of the AI Practitioner’s Blog. When I started the blog I jumped right into the content without a proper introduction. While I been in software development for many years, my only qualifications for writing a blog about AI is my experiences using the technology in anger creating real-world applications.</p>

<p>When I started the blog, my goal was to create a resource for professionals interested in the practical applications of artificial intelligence. By sharing my experences I hoped to provide insights and guidance to those looking to leverage AI in their own projects and organizations.</p>

</div>
        </div>
      </li><li><div class="post-item"><a href="/AIAGSD3/" class="post-image-link">
              <img src="/assets/images/2025-12-30/header-AIAGSD3.jpg" alt="AI Assisted Greenfield Software Development, Part 3: Generating the Process Instruction Files" class="post-thumbnail" />
            </a><div class="post-content">
            <span class="post-meta">Dec 30, 2025</span>
            <h3>
              <a class="post-link" href="/AIAGSD3/">
                AI Assisted Greenfield Software Development, Part 3: Generating the Process Instruction Files
              </a>
            </h3><p>This is the 3rd post in the series on AI assisted greenfield software development. This post builds on the first <a href="https://www.codemag.com/blog/AIPractitioner/AIAGSD1" target="_blank">AI-Assisted Greenfield Software Development, Part 1: Business Requirements</a> and subsequent posts. If you haven’t read these posts, you might consider starting there.</p>

<p>In Part 1 we defined the high-level business requirements and in Part 2 we started building out the scaffolding supporting AI code generation. In part 3, we’ll continue to add guidance for AI code generation. Starting with project guidance and process definitions, we’ll create prompts that create project overview instructions, AI code generation guidance, and Git workflow instructions.</p>

</div>
        </div>
      </li><li><div class="post-item"><a href="/WTBD/" class="post-image-link">
              <img src="/assets/images/2025-12-01/header-WTBD.jpg" alt="What&#39;s the Big Deal?" class="post-thumbnail" />
            </a><div class="post-content">
            <span class="post-meta">Dec 1, 2025</span>
            <h3>
              <a class="post-link" href="/WTBD/">
                What&#39;s the Big Deal?
              </a>
            </h3><p>A look at the revolutionary impact of AI on software development, comparing it to previous paradigm shifts in programming. This post explores how natural language coding is changing the way we build software and why this transformation is different from past technological advances.</p>

</div>
        </div>
      </li><li><div class="post-item"><a href="/AIAGSD2/" class="post-image-link">
              <img src="/assets/images/2025-09-24/header-AIAGSD2.jpg" alt="AI-Assisted Greenfield Software Development, Part 2: Core Instructions" class="post-thumbnail" />
            </a><div class="post-content">
            <span class="post-meta">Sep 24, 2025</span>
            <h3>
              <a class="post-link" href="/AIAGSD2/">
                AI-Assisted Greenfield Software Development, Part 2: Core Instructions
              </a>
            </h3><p>This is the second post in the series on AI assisted greenfield software development. This post builds on the first post <a href="https://www.codemag.com/blog/AIPractitioner/AIAGSD1" target="_blank">AI-Assisted Greenfield Software Development - Part 1 Business Requirements</a>. If you haven’t read that post, you might want to start there.</p>

<p>In this post I’ll cover the instructions, prompts, and chat modes I used to start to lay down the guidance for turning requirements into code. These files are critical for controlling the AI output and having a comprehensive set of instructions, prompts, and chat modes greatly increase the chances of getting AI to produce something usable.</p>

</div>
        </div>
      </li><li><div class="post-item"><a href="/SIWT/" class="post-image-link">
              <img src="/assets/images/2025-08-30/header-SIWT.jpg" alt="Sharing Instructions with the Team" class="post-thumbnail" />
            </a><div class="post-content">
            <span class="post-meta">Aug 30, 2025</span>
            <h3>
              <a class="post-link" href="/SIWT/">
                Sharing Instructions with the Team
              </a>
            </h3><p>When working with GitHub Copilot across multiple projects, you’ll quickly face a common challenge: how do you share generic instructions (ie. coding standards and best practices) with team members working on different projects without duplicating instruction files in every repository? This post walks you through prompting Copilot to implement a solution leveraging symlinks and junction points.</p>

</div>
        </div>
      </li><li><div class="post-item"><a href="/AIAGSD1/" class="post-image-link">
              <img src="/assets/images/2025-08-30/header-AIAGSD01.jpg" alt="AI-Assisted Greenfield Software Development, Part 1: Business Requirements" class="post-thumbnail" />
            </a><div class="post-content">
            <span class="post-meta">Aug 30, 2025</span>
            <h3>
              <a class="post-link" href="/AIAGSD1/">
                AI-Assisted Greenfield Software Development, Part 1: Business Requirements
              </a>
            </h3><p>This post starts a new series on greenfield software development. The goal is to show the development of a solution starting with the initial context and adding to the solution incrementally. Hopefully you’ll get a sense for what it’s like to build real-world solutions with the assistance of Copilot.</p>

<p>In this first installment we’ll look at the initial context provided to Copilot. This will include the initial instructions and the first prompts submitted to Copilot.</p>

</div>
        </div>
      </li><li><div class="post-item"><a href="/GHCPCM/" class="post-image-link">
              <img src="/assets/images/2025-07-30/header-GHCPCM.jpg" alt="Modes of Chatting with GitHub Copilot" class="post-thumbnail" />
            </a><div class="post-content">
            <span class="post-meta">Jul 30, 2025</span>
            <h3>
              <a class="post-link" href="/GHCPCM/">
                Modes of Chatting with GitHub Copilot
              </a>
            </h3><p>In this post I’ll explore GitHub Copilot chat modes. I’ll cover the built-in chat modes and custom chat modes. We’ll dive into custom chat modes and look at some examples.</p>

<p>To be clear, when I reference Copilot, I’m referring to GitHub Copilot, not any other Microsoft Copilot-branded AI.</p>

</div>
        </div>
      </li><li><div class="post-item"><a href="/UIAI4/" class="post-image-link">
              <img src="/assets/images/2025-05-29/header-UIAI4.jpg" alt="Developing User Interfaces with GitHub Copilot, Part 4" class="post-thumbnail" />
            </a><div class="post-content">
            <span class="post-meta">May 29, 2025</span>
            <h3>
              <a class="post-link" href="/UIAI4/">
                Developing User Interfaces with GitHub Copilot, Part 4
              </a>
            </h3><p>In the conclusion to this series on AI assisted UI development, I’ll have GitHub Copilot (GHC) add client-side sorting to a data table. If you missed any of the previous posts, you can find them here: <a href="https://www.codemag.com/Blog/AIPractitioner/UIAI1" target="_blank">Part 1</a>, <a href="https://www.codemag.com/Blog/AIPractitioner/UIAI2" target="_blank">Part 2</a>, and <a href="https://www.codemag.com/Blog/AIPractitioner/UIAI3" target="_blank">Part 3</a>.</p>

</div>
        </div>
      </li><li><div class="post-item"><a href="/UIAI3/" class="post-image-link">
              <img src="/assets/images/2025-04-30/header-UIAI3.jpg" alt="Developing User Interfaces with GitHub Copilot, Part 3" class="post-thumbnail" />
            </a><div class="post-content">
            <span class="post-meta">Apr 29, 2025</span>
            <h3>
              <a class="post-link" href="/UIAI3/">
                Developing User Interfaces with GitHub Copilot, Part 3
              </a>
            </h3><p>This post is the third installment in the series on AI assisted UI development. While this post is largely stand-alone, consider reading parts <a href="https://www.codemag.com/blog/AIPractitioner/UIAI" target="_blank">1</a> and <a href="https://www.codemag.com/Blog/AIPractitioner/UIAI2" target="_blank">2</a> before reading this post.</p>

<p>We’ve looked at using AI to create and add UI components in prior posts. In this post I’ll add a data visualization to a page.</p>

</div>
        </div>
      </li><li><div class="post-item"><a href="/UIAI2/" class="post-image-link">
              <img src="/assets/images/2025-03-29/header-UIAI2.jpg" alt="Developing User Interfaces with GitHub Copilot, Part 2" class="post-thumbnail" />
            </a><div class="post-content">
            <span class="post-meta">Mar 29, 2025</span>
            <h3>
              <a class="post-link" href="/UIAI2/">
                Developing User Interfaces with GitHub Copilot, Part 2
              </a>
            </h3><p>This is the second installment of my series on using Copilot to implement user interfaces. It does build on the topics discussed in part one, so if you missed it you can check it out <a href="https://www.codemag.com/blog/AIPractitioner/UIAI">here</a>.</p>

<p>In this article, I (well, Copilot) will expand on the implementation of the <code class="language-plaintext highlighter-rouge">owner-select</code> drop-down by encapsulating the drop-down logic into a new vue component and then replacing the implementation on the <code class="language-plaintext highlighter-rouge">Active Leads by Owner</code> vue with the new component.</p>

</div>
        </div>
      </li><li><div class="post-item"><a href="/UIAI1/" class="post-image-link">
              <img src="/assets/images/2025-02-24/header-UIAI1.jpg" alt="Developing User Interfaces with GitHub Copilot, Part 1" class="post-thumbnail" />
            </a><div class="post-content">
            <span class="post-meta">Feb 24, 2025</span>
            <h3>
              <a class="post-link" href="/UIAI1/">
                Developing User Interfaces with GitHub Copilot, Part 1
              </a>
            </h3><p>In the next few posts I will explore techniques for creating and maintaining user interfaces leveraging GitHub Copilot. Using real-world examples, I’ll show how AI handles making UI modifications. Including:</p>

<ul>
  <li>Adding new controls to an existing page</li>
  <li>Creating components that can be shared with multiple pages</li>
  <li>Creating data visualizations</li>
  <li>Adding client-side sorting to data tables.</li>
</ul>

</div>
        </div>
      </li><li><div class="post-item"><a href="/AIDI/" class="post-image-link">
              <img src="/assets/images/2025-01-30/header-AIDI.jpg" alt="Adding Dependency Injection to an Existing Solution" class="post-thumbnail" />
            </a><div class="post-content">
            <span class="post-meta">Jan 29, 2025</span>
            <h3>
              <a class="post-link" href="/AIDI/">
                Adding Dependency Injection to an Existing Solution
              </a>
            </h3><p>Modernizing legacy code can feel like renovating an old house – you know the foundation is solid, but there are improvements to be made. This article explores how to improve the maintainability and test-ability of existing code by introducing dependency injection.</p>

<p>Sometimes when working with legacy code, the code is not as testable as you may like. Making the code more testable requires, in part, to loosen tight dependencies in order to reduce the scope of the code under test.</p>

</div>
        </div>
      </li><li><div class="post-item"><a href="/CP4TA/" class="post-image-link">
              <img src="/assets/images/2024-12-13/header-CP4TA.jpg" alt="Test Generation Using GitHub Copilot" class="post-thumbnail" />
            </a><div class="post-content">
            <span class="post-meta">Dec 12, 2024</span>
            <h3>
              <a class="post-link" href="/CP4TA/">
                Test Generation Using GitHub Copilot
              </a>
            </h3><p>Using AI in a production application is risky, particularly if you are new to working with NLM-generated code. This post will show how you can get started using AI in a production application by leveraging AI’s ability to generate test automation.</p>

<p>If you’re hesitant to apply AI directly to a production codebase, that hesitation is well-grounded. Test automation is one area of your code that is begging for a little help from AI.</p>

</div>
        </div>
      </li><li><div class="post-item"><a href="/UPGHC/" class="post-image-link">
              <img src="/assets/images/2024-11-11/header-UPGHC.jpg" alt="Unleashing the Power of GitHub Copilot in Visual Studio Code" class="post-thumbnail" />
            </a><div class="post-content">
            <span class="post-meta">Nov 10, 2024</span>
            <h3>
              <a class="post-link" href="/UPGHC/">
                Unleashing the Power of GitHub Copilot in Visual Studio Code
              </a>
            </h3><p>In recent years, AI has been revolutionizing the way we code. One of the most exciting developments in this field is GitHub Copilot, an AI-powered code assistant developed by GitHub in collaboration with OpenAI. It leverages machine learning models trained on billions of lines of public code, allowing it to understand context and provide relevant suggestions. Whether you’re writing a new function or fixing a bug, Copilot is there to help streamline your coding process.</p>

</div>
        </div>
      </li><li><div class="post-item"><a href="/BDPwAI/" class="post-image-link">
              <img src="/assets/images/2024-10-14/header-BDPwAI.jpg" alt="Boosting Developer Productivity with AI Tools and Effective Strategies" class="post-thumbnail" />
            </a><div class="post-content">
            <span class="post-meta">Oct 13, 2024</span>
            <h3>
              <a class="post-link" href="/BDPwAI/">
                Boosting Developer Productivity with AI Tools and Effective Strategies
              </a>
            </h3><p>The phrase “developers will not be replaced by AI, they’ll be replaced by developers that use AI” underscores a critical shift in the tech industry. It highlights that AI is not a threat to developers’ jobs but rather a powerful tool that can enhance their capabilities. Developers who embrace AI can automate repetitive tasks, gain deeper insights through data analysis, and accelerate their coding processes.</p>

</div>
        </div>
      </li></ul>

    <p class="rss-subscribe">subscribe <a href="/feed.xml">via RSS</a></p></div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">AI Practitioner</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">John Michael Miller</li><li><a class="u-email" href="mailto:AIPractitioner@pdata.com">AIPractitioner@pdata.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>jMM&#39;s AI Practitioner Blog</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
